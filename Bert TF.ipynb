{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "import requests\n",
    "request = requests.get(\"https://drive.google.com/uc?export=download&id=1wHt8PsMLsfX5yNSqrt2fSTcb8LEiclcf\")\n",
    "with open(\"data.zip\", \"wb\") as file:\n",
    "    file.write(request.content)\n",
    "\n",
    "# Unzip data\n",
    "import zipfile\n",
    "with zipfile.ZipFile('data.zip') as zip:\n",
    "    zip.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load data and set labels\n",
    "#data_complaint = pd.read_csv('data/complaint1700.csv')\n",
    "#data_complaint['label'] = 0\n",
    "#data_non_complaint = pd.read_csv('data/noncomplaint1700.csv')\n",
    "#data_non_complaint['label'] = 1\n",
    "\n",
    "# Concatenate complaining and non-complaining data\n",
    "#data = pd.concat([data_complaint, data_non_complaint], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Drop 'airline' column\n",
    "#data.drop(['airline'], inplace=True, axis=1)\n",
    "\n",
    "# Display 5 random samples\n",
    "#data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD TWEET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/tweets.csv')\n",
    "data = data.sample(frac = 1)  #shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>904725</th>\n",
       "      <td>On the bus to NYC   http://yfrog.com/08kaifj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385628</th>\n",
       "      <td>@deadstarx guten morgen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262870</th>\n",
       "      <td>my accomplishment of rationality and reason: m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657119</th>\n",
       "      <td>Leaving</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530786</th>\n",
       "      <td>@TheEllenShow ---Ellen I love your energy. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  sentiment\n",
       "904725        On the bus to NYC   http://yfrog.com/08kaifj          1\n",
       "1385628                           @deadstarx guten morgen           1\n",
       "262870   my accomplishment of rationality and reason: m...          0\n",
       "657119                                            Leaving           0\n",
       "1530786  @TheEllenShow ---Ellen I love your energy. htt...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= data[:1000]\n",
    "data.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.text.values\n",
    "y = data.sentiment.values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>89653</td>\n",
       "      <td>Hey @united, I had to pay $200 change fee to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>79273</td>\n",
       "      <td>Never cease to be amazed by @AmericanAir - So ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>99528</td>\n",
       "      <td>@SouthwestAir my bag was lost, and according t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>43433</td>\n",
       "      <td>@SouthwestAir - Sucks. Never fly again. This m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>70932</td>\n",
       "      <td>@kingisafink @united all bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              tweet\n",
       "2337  89653  Hey @united, I had to pay $200 change fee to b...\n",
       "2042  79273  Never cease to be amazed by @AmericanAir - So ...\n",
       "2600  99528  @SouthwestAir my bag was lost, and according t...\n",
       "1104  43433  @SouthwestAir - Sucks. Never fly again. This m...\n",
       "1835  70932                       @kingisafink @united all bad"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "test_data = pd.read_csv('data/test_data.csv')\n",
    "\n",
    "# Keep important columns\n",
    "test_data = test_data[['id', 'tweet']]\n",
    "\n",
    "# Display 5 samples from the test data\n",
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mikaelcarlsson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# Uncomment to download \"stopwords\"\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_preprocessing(s):\n",
    "    \"\"\"\n",
    "    - Lowercase the sentence\n",
    "    - Change \"'t\" to \"not\"\n",
    "    - Remove \"@name\"\n",
    "    - Isolate and remove punctuations except \"?\"\n",
    "    - Remove other special characters\n",
    "    - Remove stop words except \"not\" and \"can\"\n",
    "    - Remove trailing whitespace\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Change 't to 'not'\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    # Remove @name\n",
    "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
    "    # Isolate and remove punctuations except '?'\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
    "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Remove stopwords except 'not' and 'can'\n",
    "    s = \" \".join([word for word in s.split()\n",
    "                  if word not in stopwords.words('english')\n",
    "                  or word in ['not', 'can']])\n",
    "    # Remove trailing whitespace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    \n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 s, sys: 379 ms, total: 1.98 s\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Preprocess text\n",
    "X_train_preprocessed = np.array([text_preprocessing(text) for text in X_train])\n",
    "X_val_preprocessed = np.array([text_preprocessing(text) for text in X_val])\n",
    "\n",
    "# Calculate TF-IDF\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                         binary=True,\n",
    "                         smooth_idf=False)\n",
    "X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\n",
    "X_val_tfidf = tf_idf.transform(X_val_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "def get_auc_CV(model):\n",
    "    \"\"\"\n",
    "    Return the average AUC score from cross-validation.\n",
    "    \"\"\"\n",
    "    # Set KFold to shuffle data before the split\n",
    "    kf = StratifiedKFold(5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Get AUC scores\n",
    "    auc = cross_val_score(\n",
    "        model, X_train_tfidf, y_train, scoring=\"roc_auc\", cv=kf)\n",
    "\n",
    "    return auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=1.0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=1.1 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=1.2000000000000002 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=1.3000000000000003 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=1.4000000000000004 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=1.5000000000000004 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=1.6000000000000005 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=1.7000000000000006 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=1.8000000000000007 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=1.9000000000000008 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=2.000000000000001 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=2.100000000000001 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=2.200000000000001 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=2.300000000000001 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=2.4000000000000012 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=2.5000000000000013 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=2.6000000000000014 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=2.7000000000000015 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=2.8000000000000016 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=2.9000000000000017 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=3.0000000000000018 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=3.100000000000002 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=3.200000000000002 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=3.300000000000002 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=3.400000000000002 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=3.500000000000002 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=3.6000000000000023 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=3.7000000000000024 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=3.8000000000000025 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=3.9000000000000026 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=4.000000000000003 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=4.100000000000003 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=4.200000000000003 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=4.3000000000000025 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=4.400000000000003 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=4.5000000000000036 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=4.600000000000003 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=4.700000000000003 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=4.800000000000003 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=4.900000000000004 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=5.0000000000000036 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=5.100000000000003 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=5.200000000000004 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=5.300000000000004 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=5.400000000000004 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=5.5000000000000036 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=5.600000000000004 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=5.700000000000005 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=5.800000000000004 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=5.900000000000004 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=6.000000000000004 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=6.100000000000005 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=6.200000000000005 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=6.300000000000004 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=6.400000000000005 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=6.500000000000005 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=6.600000000000005 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=6.700000000000005 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=6.800000000000005 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=6.900000000000006 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=7.000000000000005 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=7.100000000000005 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=7.2000000000000055 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=7.300000000000006 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=7.400000000000006 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=7.500000000000005 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=7.600000000000006 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=7.700000000000006 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=7.800000000000006 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=7.900000000000006 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=8.000000000000007 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=8.100000000000007 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=8.200000000000006 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=8.300000000000006 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=8.400000000000006 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=8.500000000000007 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=8.600000000000007 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=8.700000000000006 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=8.800000000000008 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=8.900000000000007 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=9.000000000000007 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=9.100000000000007 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=9.200000000000006 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=9.300000000000008 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=9.400000000000007 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=9.500000000000007 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=9.600000000000009 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=9.700000000000008 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=9.800000000000008 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=9.900000000000007 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha:  9.8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "res = pd.Series([get_auc_CV(MultinomialNB(i))\n",
    "                 for i in np.arange(1, 10, 0.1)],\n",
    "                index=np.arange(1, 10, 0.1))\n",
    "\n",
    "best_alpha = np.round(res.idxmax(), 2)\n",
    "print('Best alpha: ', best_alpha)\n",
    "\n",
    "plt.plot(res)\n",
    "plt.title('AUC vs. Alpha')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('AUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7855\n",
      "Accuracy: 72.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute predicted probabilities\n",
    "nb_model = MultinomialNB(alpha=1.8)\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "probs = nb_model.predict_proba(X_val_tfidf)\n",
    "\n",
    "# Evaluate the classifier\n",
    "evaluate_roc(probs, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  @amazingphoebe i would have preferred to have known you didn't want me to go, then to think you don't care \n",
      "Processed:  i would have preferred to have known you didn't want me to go, then to think you don't care\n"
     ]
    }
   ],
   "source": [
    "# Print sentence 0\n",
    "print('Original: ', X[0])\n",
    "print('Processed: ', text_preprocessing(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_bert(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  73\n"
     ]
    }
   ],
   "source": [
    "# Concatenate train data and test data\n",
    "#all_tweets = np.concatenate([data.tweet.values, test_data.tweet.values])\n",
    "all_tweets = np.concatenate([data.text.values, test_data.tweet.values])\n",
    "\n",
    "# Encode our concatenated data\n",
    "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
    "\n",
    "# Find the maximum length\n",
    "max_len = max([len(sent) for sent in encoded_tweets])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  @amazingphoebe i would have preferred to have known you didn't want me to go, then to think you don't care \n",
      "Token IDs:  [101, 1045, 2052, 2031, 6871, 2000, 2031, 2124, 2017, 2134, 1005, 1056, 2215, 2033, 2000, 2175, 1010, 2059, 2000, 2228, 2017, 2123, 1005, 1056, 2729, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Specify `MAX_LEN`\n",
    "MAX_LEN = 64\n",
    "\n",
    "# Print sentence 0 and its encoded token ids\n",
    "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
    "print('Original: ', X[0])\n",
    "print('Token IDs: ', token_ids)\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 µs, sys: 0 ns, total: 40 µs\n",
      "Wall time: 44.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 50, 2\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def initialize_model(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1    |   20    |   0.641000   |     -      |     -     |  191.71  \n",
      "   1    |   28    |   0.562884   |     -      |     -     |   63.53  \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.619451   |  0.573886  |   67.19   |  262.68  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.404545   |     -      |     -     |  199.77  \n",
      "   2    |   28    |   0.302160   |     -      |     -     |   62.73  \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.376301   |  0.626092  |   70.31   |  270.07  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)    # Set seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, val_dataloader)\n",
    "\n",
    "# Evaluate the Bert classifier\n",
    "evaluate_roc(probs, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the train set and the validation set\n",
    "full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
    "full_train_sampler = RandomSampler(full_train_data)\n",
    "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
    "\n",
    "# Train the Bert Classifier on the entire training data\n",
    "set_seed(42)\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "train(bert_classifier, full_train_dataloader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run `preprocessing_for_bert` on the test set\n",
    "print('Tokenizing data...')\n",
    "test_inputs, test_masks = preprocessing_for_bert(test_data.tweet)\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, test_dataloader)\n",
    "\n",
    "# Get predictions from the probabilities\n",
    "threshold = 0.9\n",
    "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
    "\n",
    "# Number of tweets predicted non-negative\n",
    "print(\"Number of tweets predicted non-negative: \", preds.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = test_data[preds==1]\n",
    "list(output.sample(20).tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
